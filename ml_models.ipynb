{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load Libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#Utils\n",
    "from ml_utils import *\n",
    "from machine_learning_models import *\n",
    "from fingerprints import *\n",
    "import random\n",
    "from IPython.core.display_functions import display\n",
    "from tqdm.notebook import tqdm\n",
    "#Sklearn\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models Parameters\n",
    "### Select the desired parameters to be used by regression models\n",
    "<p>\n",
    "<li> <b>model_list</b>: ML/DL models for regression (kNN: k-neirest neighbor, SVR: Support Vector Regression, RFR: Random Forest Regression, DNN: Deep Neural Network, MR: Median regression)</li>\n",
    "</p>\n",
    "<p>\n",
    "<li> <b>cv_fold</b>: Number do data splits (trials) to be performed</li>\n",
    "</p>\n",
    "<p>\n",
    "<li> <b>opt_metric</b>: Optimization metric to be use for model optimization (MAE: 'neg_mean_absolute_error', MSE: ‘neg_mean_squared_error’)</li>\n",
    "</p>\n",
    "<p>\n",
    "<li> <b>data_order</b>: Different data orders ('regular': Normal potency (y) order, 'y_rand': Randomized potency values) </li>\n",
    "</p>\n",
    "<p>\n",
    "<li> <b>compound_sets</b>: Compound sets to be generated ('Complete set': 100% compounds, 'Random set': Random set of compounds, 'Diverse set': Chemical diverse set of compounds) </li>\n",
    "</p>\n",
    "<p>\n",
    "<li> <b>compound_sets_size</b>: Compound sets size to be generated for 'Random' and 'Diverse' based on the size of the respective 'Complete' ('Complete set': 100% compounds, 'Random set': 25%, 'Diverse set': 25%) </li>\n",
    "</p>\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_list = ['kNN', 'SVR', 'RFR', 'DNN', 'MR']\n",
    "cv_folds=10\n",
    "opt_metric = \"neg_mean_absolute_error\"\n",
    "data_order = ['regular', 'y_rand']\n",
    "compound_sets = ['Complete set', 'Random set', 'Diverse set']\n",
    "compound_sets_size = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Load Data\n",
    "### Load compound database to be used for the regression models\n",
    "\n",
    "<li> <b>db_path</b>: dataset full path</li>\n",
    "</p>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Database path\n",
    "db_path = './dataset/'\n",
    "# Load actives dB\n",
    "regression_db = pd.read_csv(os.path.join(db_path, f'chembl_30_IC50_10_tids_1000_CPDs.csv'))\n",
    "# Regression Compound Targets\n",
    "regression_tids = regression_db.chembl_tid.unique()[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Final Dataframes\n",
    "performance_train_df = pd.DataFrame()\n",
    "predictions_train_df = pd.DataFrame()\n",
    "performance_test_df = pd.DataFrame()\n",
    "predictions_test_df = pd.DataFrame()\n",
    "parameter_resume = []\n",
    "\n",
    "# Generate Molecular Fingerprints\n",
    "morgan_radius2 = FoldedMorganFingerprint(radius=2)\n",
    "morgan_radius2.fit_smiles(regression_db.nonstereo_aromatic_smiles.tolist())\n",
    "\n",
    "for data_ord in data_order:\n",
    "    for target in tqdm(regression_tids):\n",
    "        for approach in compound_sets:\n",
    "            for i in range(3):\n",
    "                print(f'Training on {target}')\n",
    "\n",
    "                # Select Target Database\n",
    "                regression_db_tid = regression_db.loc[regression_db.chembl_tid == target]\n",
    "\n",
    "                # Constructing ChEMBL Dataset\n",
    "                fp_matrix = morgan_radius2.transform_smiles(regression_db_tid.nonstereo_aromatic_smiles.tolist())\n",
    "\n",
    "                # Randomized Class potency\n",
    "                if data_ord == \"y_rand\":\n",
    "                    random.shuffle(regression_db_tid.pPot.values)\n",
    "\n",
    "                # Constructing Dataset\n",
    "                dataset = Dataset(fp_matrix, np.array(regression_db_tid.pPot.values))\n",
    "                dataset.add_instance(\"target\", regression_db_tid.chembl_tid.values)\n",
    "                dataset.add_instance(\"smiles\", regression_db_tid.nonstereo_aromatic_smiles.values)\n",
    "\n",
    "                # Data Sampling Approaches\n",
    "                if approach == 'Diverse set':\n",
    "                    fp_bit_vec = ECFP4(regression_db_tid.nonstereo_aromatic_smiles.tolist())\n",
    "                    mol_idx = maxminpicker(fp_bit_vec, compound_sets_size, seed=i+1)\n",
    "                    dataset = dataset[mol_idx]\n",
    "\n",
    "                elif approach == 'Random set':\n",
    "                    random.seed(i+1)\n",
    "                    mol_idx = random.sample([idx for idx in range(dataset.features.shape[0])], int(compound_sets_size*dataset.features.shape[0]))\n",
    "                    dataset = dataset[mol_idx]\n",
    "\n",
    "                # Split dataset into TR and TE\n",
    "                data_splitter = ShuffleSplit(n_splits=cv_folds, random_state=20021997, test_size=0.2)\n",
    "                for trial, (train_idx, test_idx) in enumerate(data_splitter.split(dataset.features, dataset.target)):\n",
    "                    print(f'Starting Trial {trial}')\n",
    "\n",
    "                    #Defining Training and Test sets\n",
    "                    training_set = dataset[train_idx]\n",
    "                    test_set = dataset[test_idx]\n",
    "\n",
    "                    for model in model_list:\n",
    "                        print(f'Training {model}')\n",
    "\n",
    "                        # Save ML models\n",
    "                        model_fpath = create_directory(f\"./regression_results/trained_models/{model}/\", verbose=False)\n",
    "                        if model == 'DNN':\n",
    "                            ml_model = DNN(training_set, model, training_set.features.shape[1], seed=trial)\n",
    "                            model_fpath += \".h5\"\n",
    "                            ml_model.model.save(model_fpath)\n",
    "                        else:\n",
    "                            ml_model = MLModel(training_set, model)\n",
    "                            model_fpath += \".p.gz\"\n",
    "\n",
    "                        #Best model parameters dictionary\n",
    "                        opt_parameters_dict = {'model': model,\n",
    "                                               'trial': trial,\n",
    "                                               'Target ID': target}\n",
    "                        for param, value in ml_model.best_params.items():\n",
    "                            opt_parameters_dict[param] = value\n",
    "                        parameter_resume.append(opt_parameters_dict)\n",
    "\n",
    "                        # TRAIN\n",
    "                        #Model Evaluation\n",
    "                        model_eval_train = Model_Evaluation(ml_model, training_set)\n",
    "\n",
    "                        #Performance df\n",
    "                        performance_train = model_eval_train.pred_performance\n",
    "                        performance_train[\"trial\"] = trial\n",
    "                        performance_train[\"Approach\"] = approach\n",
    "                        performance_train[\"Approach_trial\"] = i\n",
    "                        performance_train_df = pd.concat([performance_train_df, performance_train])\n",
    "\n",
    "                        # TEST\n",
    "                        #Model Evaluation\n",
    "                        model_eval_test = Model_Evaluation(ml_model, test_set)\n",
    "\n",
    "                        #Performance df\n",
    "                        performance_test = model_eval_test.pred_performance\n",
    "                        performance_test[\"trial\"] = trial\n",
    "                        performance_test[\"Approach\"] = approach\n",
    "                        performance_test[\"Approach_trial\"] = i\n",
    "                        performance_test_df = pd.concat([performance_test_df, performance_test])\n",
    "\n",
    "                        # Prediction df\n",
    "                        predictions_test = model_eval_test.predictions\n",
    "                        predictions_test[\"trial\"] = trial\n",
    "                        predictions_test[\"Approach\"] = approach\n",
    "                        predictions_test[\"Approach_trial\"] = i\n",
    "                        predictions_test_df = pd.concat([predictions_test_df, predictions_test])\n",
    "\n",
    "                if approach == 'Complete set':\n",
    "                    break\n",
    "\n",
    "    # All Dataframes\n",
    "    parameter_df = pd.DataFrame(parameter_resume)\n",
    "    display(performance_test_df)\n",
    "\n",
    "    # Save results\n",
    "    result_path = './regression_results/'\n",
    "    if data_ord == 'y_rand':\n",
    "        performance_train_df.to_csv(os.path.join(result_path, f'performance_train_y_rand.csv'))\n",
    "        performance_test_df.to_csv(os.path.join(result_path, f'performance_test_y_rand.csv'))\n",
    "        parameter_df.to_csv(os.path.join(result_path, f'model_best_parameters_y_rand.csv'))\n",
    "        predictions_test_df.to_csv(os.path.join(result_path, f'predictions_test_y_rand.csv'))\n",
    "    else:\n",
    "        performance_train_df.to_csv(os.path.join(result_path, f'performance_train.csv'))\n",
    "        performance_test_df.to_csv(os.path.join(result_path, f'performance_test.csv'))\n",
    "        parameter_df.to_csv(os.path.join(result_path, f'model_best_parameters.csv'))\n",
    "        predictions_test_df.to_csv(os.path.join(result_path, f'predictions_test.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}